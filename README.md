# DeapLearning-ReverseMentoring

## Lecture 1

### 1.1 Machine Learning Introduction

* Machine Learning의 정의
* Machine Learning의 분류
  * 지도학습 (supervised learning)
    * KNN classification
    * linear regression
  * 비지도학습(unsupervised learning)
    * K-means clustering

### 1.2 Linear Regression
* Gradient Descent
  * Learning Rate
* Overfitting
  * Regularization
  * Early stopping
    
### 1.3 Gradient Descent Optimization Algorithms
* Stochastic Gradient Descent (SGD)
* Momentum
* Adagrad
* Rmsprop

### 1.4 Regularization
* L1 Regularization
* L2 Regularization

### 1.5 Linear classification


### 1.6 실습 코드
* [01.Python Library Tutorial](https://github.com/ibks-hyobin/deeplearning-reverseMentoring/blob/master/01.Python%20Library%20Tutorial%20(numpy%2Cmatplotlib).ipynb)
* [02.Linear Regression](https://github.com/ibks-hyobin/deeplearning-reverseMentoring/blob/master/02.Linear%20Regression.ipynb)
* 
* 

### 참고 자료
* [stanford university cs231 Lecture 2, Lecture 3](http://cs231n.stanford.edu/2018/syllabus.html)
* [머신러닝, 1시간으로 입문하기](https://www.youtube.com/watch?v=j3za7nv7RfI&t=2047s)
* [머신러닝의 기초 - 선형 회귀 한 번에 제대로 이해하기](https://www.youtube.com/watch?v=ve6gtpZV83E&t=1619s)
* [Gradient Descent Optimization Algorithms 정리](http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html)


## Lecture 2

## Lecture 3
